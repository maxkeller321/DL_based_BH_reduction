About DL-BeamHardening 
===========


This repository contains the work related to the deep-learning based beam hardening removal. 


Setup-Project: 
===========
**Install Python packages:**  
```pip install torch pytorch-lightning torchmetrics matplotlib h5py numpy einops pyqt5``` 

**Build Voxie & Model-load extension:**  
```tools/build.sh```  

Repository-Structure: 
===========
ðŸ“¦dl_beamhardening   
 â”£ ðŸ“‚aRTist_project  
 â”ƒ â”£ Example aRTist projects with IPVS settings       
 â”ƒ â”— ðŸ“‚Spektren  
 â”ƒ â”ƒ â”— Mono & poly (IPVS-Setup) spectrum files       
 â”£ ðŸ“‚data_analysis_scripts  
 â”ƒ â”— Scripts for calculating mean gray value, data analysis & .tiff plot   
 â”£ ðŸ“‚dataset_preparation_scripts   
 â”ƒ â”£ ðŸ“‚preprocessing  
 â”ƒ â”ƒ â”— Script for flatfield correction  
 â”ƒ â”£ ðŸ“‚tiff_to_hdf5  
 â”ƒ â”ƒ â”£ ðŸ“‚stuff  
 â”ƒ â”ƒ â”ƒ â”— Various debug, plot & volume compare scripts  
 â”ƒ â”ƒ â”— Tiff to hdf5 converter script  
 â”ƒ â”— Script for transposing & cutting volumes  
 â”£ ðŸ“‚doc 
 â”ƒ â”— OneNote notebook & exported OneNote pages    
 â”£ ðŸ“‚models  
 â”ƒ â”£ ðŸ“‚checkpoints    
 â”ƒ â”ƒ â”— CNN-AI-CT checkpoints/traces that can be loaded by voxie   
 â”ƒ â”£ ðŸ“‚test_cases  
 â”ƒ â”ƒ â”— unittest, to check dataloader logic   
 â”ƒ â”£ ðŸ“œCNN_ai_ct.py  
 â”ƒ â”£ ðŸ“œCNN_ai_ct_silu.py  (CNN-AI-CT with SILU-Activations)     
 â”ƒ â”£ ðŸ“œCNN_ai_ct_skip.py  (CNN-AI-CT with SKIP-Connections)     
 â”ƒ â”£ ðŸ“œCNN_ai_ct_trans_skip.py   (CNN-AI-CT with SKIP-Connection & extra Linear-Layers)   
 â”ƒ â”£ ðŸ“œIRR_CNN_ai_ct.py  (CNN-AI-CT with Iterative-Residual-Refinement)   
 â”ƒ â”£ ðŸ“œPerceiverModel.py  (DeepMinds Perceiver-Model)   
 â”ƒ â”£ ðŸ“œUnet.py   
 â”ƒ â”£ ðŸ“œdataloader.py  
 â”ƒ â”£ ðŸ“œdatasets.json  (Contains path of all datasets)  
 â”ƒ â”£ ðŸ“œdebug_datasets.json    
 â”ƒ â”£ ðŸ“œnoisy_indexes.json  (Contains indices of slices that contain only noise 256x256 patches)    
 â”ƒ â”£ ðŸ“œparseTorchScript.py  
 â”ƒ â”£ ðŸ“œremoveBeamHardening.py (Remove Beam-Hardening from volume with passed checkpoint)   
 â”ƒ â”£ ðŸ“œrunModel.py (Script to load & test checkpoints)      
 â”ƒ â”£ ðŸ“œtrain.py (Main script to start training & choose  models)    
 â”ƒ â”£ ðŸ“œutils.py  
 â”ƒ â”— ðŸ“œvisualization.py  
 â”£ ðŸ“‚src  
 â”ƒ â”— Extern voxie filter to load pyTorch models (traces) of CNN-AI-CT   
 â”£ ðŸ“‚subprojects  
 â”ƒ â”— ðŸ“‚voxie-intern  
 â”£ ðŸ“‚test_data  
 â”ƒ â”— small volume data for test-purposes  
 â”£ ðŸ“‚tools  
 â”ƒ â”— build script (Voxie + extension) & normalisation  script  
 â”£ ðŸ“œ.clang-format  
 â”£ ðŸ“œ.gitignore  
 â”£ ðŸ“œ.gitmodules  
 â”£ ðŸ“œREADME.md  
 â”— ðŸ“œmeson.build  

## Use-cases naming convention
> To distinguish different training runs & model checkpoints
![Use-Cases](doc/UsecasesNamingConvention.png)


Training & RunModel 
===========

For training and checkpoint loading details/ scripts check this folder on pasnas:

```/net/pasnas01/pool1/enpro-2021-voxie/training/slurm_files```

This folder contains all used slurm and corresponding bash scripts. 

Dataset preparation scripts
===========
### tiff_to_hdf5

>Converts a bunch of Tiff files into a single HDF5 file and appends meta-data needed for the reconstruction. >Manual flat-field correction can be applied if needed.  

**Run:** (Without flat-field correction): 

```
<python-interpreter> tiff_to_hdf5.py -f <path-tiff-file-folder> -o <absolute-path-of-output> -dsra <distance-source-rotation>
```

**Run:** (With flat-field correction): 

```
<python-interpreter> tiff_to_hdf5.py -f <path-tiff-file-folder> -o <absolute-path-of-output> -dsra <distance-source-rotation> -w <path-to-white-tiff-image>
```

**Hint:** 
- distance-source-rotation must be in meter [m] 
- white-image: Ct-projection image without an object and detector noise but apart from this with the same parameters as the normal projections

### reco_post_processing.py  

>Transposes and cuts the monochromatic and polychromatic >reconstructed volumes identical. 

**Run:**
```
<python-interpreter> reco_post_processing.py -fp <path-reconstructed-volume-poly-hdf5> -fm <path-reconstructed-volume-mono-hdf5> -op <output-path-poly-hdf5> -om <output-path-mono-hdf5> -fc <cutting-coefficient>  
```

**Hint:** 
- cutting-coefficient: The factor is multiplied with the mean_grey_value of the volume. Slices are then removed if the mean slice gray value is lower as this product.


Dataset analysis scripts
===========
### plot_sample_differences.py

>Create images of the slices that can be used to analyze the data:
> Poly, Mono, Poly-Mono & Histogram(Poly-Mono)

**Run:**
```
<python-interpreter> plot_sample_differences.py -f <dataset-json-file-path> -o <output-path> -ss <step-size> -dn <names-of-datasets>
```
**Hint:** 
- step-size: Each int(dataset_size/step_size) sample is written out
- names-of-datasets: Default is all
- output-looks like: ![Use-Cases](doc/AnalysisScriptExample.png)

### calculate_cutted_mean.py

>Calculates the mean gray value of a volume and appends it as meta-data. 

```
calculate_cutted_mean.py -f <dataset-json-file-path> -dn <names-of-datasets>
```

**Hint:** 
- names-of-datasets: Default is all